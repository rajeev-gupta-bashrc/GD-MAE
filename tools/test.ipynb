{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, time\n",
    "import logging\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "sys.path.insert(0, '/home/rajeev-gupta/sensyn_ws/src/GD-MAE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pcdet.models.detectors import GraphRCNN\n",
    "from pcdet.config import cfg, cfg_from_yaml_file\n",
    "from pcdet.datasets.kitti.kitti_dataset import KittiDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = './test_logs.txt'\n",
    "cfg_file = '/home/rajeev-gupta/sensyn_ws/src/GD-MAE/tools/cfgs/kitti_models/graph_rcnn_voi.yaml'\n",
    "ckpt_path = '/home/rajeev-gupta/sensyn_ws/src/GD-MAE/data/ckpts/graph_rcnn_voi_kitti.pth'\n",
    "to_cpu = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logger\n",
    "def create_logger(log_file=None, rank=0, log_level=logging.INFO):\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.setLevel(log_level if rank == 0 else 'ERROR')\n",
    "    formatter = logging.Formatter('%(asctime)s  %(levelname)5s  %(message)s')\n",
    "    console = logging.StreamHandler()\n",
    "    console.setLevel(log_level if rank == 0 else 'ERROR')\n",
    "    console.setFormatter(formatter)\n",
    "    logger.addHandler(console)\n",
    "    if log_file is not None:\n",
    "        file_handler = logging.FileHandler(filename=log_file)\n",
    "        file_handler.setLevel(log_level if rank == 0 else 'ERROR')\n",
    "        file_handler.setFormatter(formatter)\n",
    "        logger.addHandler(file_handler)\n",
    "    logger.propagate = False\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_to_gpu(batch_dict):\n",
    "    for key, val in batch_dict.items():\n",
    "        if not isinstance(val, np.ndarray):\n",
    "            continue\n",
    "        elif key in ['frame_id', 'metadata', 'calib', 'image_shape', 'image_pad_shape', 'image_rescale_shape']:\n",
    "            continue\n",
    "        else:\n",
    "            batch_dict[key] = torch.from_numpy(val).float().cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = create_logger(log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ROOT_DIR': PosixPath('/home/rajeev-gupta/sensyn_ws/src/GD-MAE'),\n",
       " 'LOCAL_RANK': 0,\n",
       " 'CLASS_NAMES': ['Car'],\n",
       " 'DATA_CONFIG': {'DATASET': 'KittiDataset',\n",
       "  'DATA_PATH': '../data/kitti',\n",
       "  'BACKEND': {'NAME': 'HardDiskBackend'},\n",
       "  'POINT_CLOUD_RANGE': [0, -40, -3, 70.4, 40, 1],\n",
       "  'DATA_SPLIT': {'train': 'train', 'test': 'test'},\n",
       "  'INFO_PATH': {'train': ['kitti_infos_train.pkl'],\n",
       "   'test': ['kitti_infos_test.pkl']},\n",
       "  'GET_ITEM_LIST': ['points', 'image', 'calib_matricies', 'gt_boxes2d'],\n",
       "  'FOV_POINTS_ONLY': True,\n",
       "  'ENABLE_SIMILAR_TYPE': True,\n",
       "  'DATA_AUGMENTOR': {'DISABLE_AUG_LIST': ['placeholder'],\n",
       "   'AUG_CONFIG_LIST': [{'NAME': 'random_world_flip',\n",
       "     'PROBABILITY': 0.5,\n",
       "     'ALONG_AXIS_LIST': ['x']},\n",
       "    {'NAME': 'random_world_rotation',\n",
       "     'PROBABILITY': 1.0,\n",
       "     'WORLD_ROT_ANGLE': [-0.78539816, 0.78539816]},\n",
       "    {'NAME': 'random_world_scaling',\n",
       "     'PROBABILITY': 1.0,\n",
       "     'WORLD_SCALE_RANGE': [0.95, 1.05]}]},\n",
       "  'POINT_FEATURE_ENCODING': {'encoding_type': 'absolute_coordinates_encoding',\n",
       "   'used_feature_list': ['x', 'y', 'z', 'intensity'],\n",
       "   'src_feature_list': ['x', 'y', 'z', 'intensity']},\n",
       "  'DATA_PROCESSOR': [{'NAME': 'mask_points_and_boxes_outside_range',\n",
       "    'REMOVE_OUTSIDE_BOXES': True},\n",
       "   {'NAME': 'shuffle_points',\n",
       "    'SHUFFLE_ENABLED': {'train': True, 'test': False}},\n",
       "   {'NAME': 'calculate_grid_size', 'VOXEL_SIZE': [0.05, 0.05, 0.1]},\n",
       "   {'NAME': 'imrescale',\n",
       "    'IMAGE_SCALES': {'train': [[640, 192], [2560, 768]],\n",
       "     'test': [[1280, 384]]},\n",
       "    'KEEP_RATIO': True},\n",
       "   {'NAME': 'imflip', 'FLIP_RATIO': {'train': 0.5, 'test': 0}},\n",
       "   {'NAME': 'imnormalize',\n",
       "    'MEAN': [104.014, 114.034, 119.917],\n",
       "    'STD': [73.603, 69.891, 70.915],\n",
       "    'TO_RGB': False},\n",
       "   {'NAME': 'impad', 'SIZE_DIVISOR': 32}],\n",
       "  '_BASE_CONFIG_': 'cfgs/dataset_configs/kitti_dataset.yaml'},\n",
       " 'MODEL': {'NAME': 'GraphRCNN',\n",
       "  'FREEZE_LAYERS': ['DynVFE',\n",
       "   'VoxelBackBone8x',\n",
       "   'HeightCompression',\n",
       "   'BaseBEVBackbone',\n",
       "   'AnchorHeadSingle',\n",
       "   'DLASeg'],\n",
       "  'IMG_BACKBONE': {'NAME': 'DLASeg',\n",
       "   'BASE_NAME': 'dla34',\n",
       "   'DOWN_RATIO': 4,\n",
       "   'LAST_LEVEL': 5},\n",
       "  'VFE': {'NAME': 'DynVFE', 'TYPE': 'mean'},\n",
       "  'BACKBONE_3D': {'NAME': 'VoxelBackBone8x'},\n",
       "  'MAP_TO_BEV': {'NAME': 'HeightCompression', 'NUM_BEV_FEATURES': 256},\n",
       "  'BACKBONE_2D': {'NAME': 'BaseBEVBackbone',\n",
       "   'LAYER_NUMS': [4, 4],\n",
       "   'LAYER_STRIDES': [1, 2],\n",
       "   'NUM_FILTERS': [64, 128],\n",
       "   'UPSAMPLE_STRIDES': [1, 2],\n",
       "   'NUM_UPSAMPLE_FILTERS': [128, 128]},\n",
       "  'DENSE_HEAD': {'NAME': 'AnchorHeadSingle',\n",
       "   'CLASS_AGNOSTIC': False,\n",
       "   'USE_DIRECTION_CLASSIFIER': True,\n",
       "   'DIR_OFFSET': 0.78539,\n",
       "   'DIR_LIMIT_OFFSET': 0.0,\n",
       "   'NUM_DIR_BINS': 2,\n",
       "   'ANCHOR_GENERATOR_CONFIG': [{'class_name': 'Car',\n",
       "     'anchor_sizes': [[3.9, 1.6, 1.56]],\n",
       "     'anchor_rotations': [0, 1.57],\n",
       "     'anchor_bottom_heights': [-1.78],\n",
       "     'align_center': False,\n",
       "     'feature_map_stride': 8,\n",
       "     'matched_threshold': 0.6,\n",
       "     'unmatched_threshold': 0.45}],\n",
       "   'TARGET_ASSIGNER_CONFIG': {'NAME': 'AxisAlignedTargetAssigner',\n",
       "    'POS_FRACTION': -1.0,\n",
       "    'SAMPLE_SIZE': 512,\n",
       "    'NORM_BY_NUM_EXAMPLES': False,\n",
       "    'MATCH_HEIGHT': False,\n",
       "    'BOX_CODER': 'ResidualCoder'},\n",
       "   'LOSS_CONFIG': {'LOSS_WEIGHTS': {'cls_weight': 1.0,\n",
       "     'loc_weight': 2.0,\n",
       "     'dir_weight': 0.2,\n",
       "     'code_weights': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}},\n",
       "  'ROI_HEAD': {'NAME': 'GraphRCNNHead',\n",
       "   'CLASS_AGNOSTIC': True,\n",
       "   'NMS_CONFIG': {'TRAIN': {'NMS_TYPE': 'nms_gpu',\n",
       "     'MULTI_CLASSES_NMS': False,\n",
       "     'NMS_PRE_MAXSIZE': 9000,\n",
       "     'NMS_POST_MAXSIZE': 512,\n",
       "     'NMS_THRESH': 0.8},\n",
       "    'TEST': {'NMS_TYPE': 'nms_gpu',\n",
       "     'MULTI_CLASSES_NMS': False,\n",
       "     'NMS_PRE_MAXSIZE': 2048,\n",
       "     'NMS_POST_MAXSIZE': 100,\n",
       "     'NMS_THRESH': 0.7}},\n",
       "   'DFVS_CONFIG': {'NUM_DVS_POINTS': 2048,\n",
       "    'NUM_FPS_POINTS': 128,\n",
       "    'HASH_SIZE': 4099,\n",
       "    'LAMBDA': 0.12,\n",
       "    'DELTA': 50,\n",
       "    'POOL_EXTRA_WIDTH': [0.5, 0.5, 0.5],\n",
       "    'NUM_BOXES_PER_PATCH': 32},\n",
       "   'IMG_CONFIG': {'IN_DIM': 64, 'MLPS': [32, 32]},\n",
       "   'ATTN_GNN_CONFIG': {'IN_DIM': 42,\n",
       "    'OUT_DIM': 512,\n",
       "    'MLPS': [64, 64, 128],\n",
       "    'CALIB_DIM': 128,\n",
       "    'EXP_MLPS': [128, 512],\n",
       "    'K': 4,\n",
       "    'USE_FEATS_DIS': False,\n",
       "    'USE_REDUCTION': False,\n",
       "    'USE_SHORT_CUT': False},\n",
       "   'TARGET_CONFIG': {'BOX_CODER': 'ResidualCoder',\n",
       "    'ROI_PER_IMAGE': 128,\n",
       "    'FG_RATIO': 0.5,\n",
       "    'SAMPLE_ROI_BY_EACH_CLASS': True,\n",
       "    'CLS_SCORE_TYPE': 'roi_iou',\n",
       "    'CLS_FG_THRESH': 0.75,\n",
       "    'CLS_BG_THRESH': 0.25,\n",
       "    'CLS_BG_THRESH_LO': 0.1,\n",
       "    'HARD_BG_RATIO': 0.8,\n",
       "    'REG_FG_THRESH': 0.55},\n",
       "   'LOSS_CONFIG': {'CLS_LOSS': 'BinaryCrossEntropy',\n",
       "    'REG_LOSS': 'WeightedSmoothL1Loss',\n",
       "    'CORNER_LOSS_REGULARIZATION': True,\n",
       "    'LOSS_WEIGHTS': {'rcnn_cls_weight': 1.0,\n",
       "     'rcnn_reg_weight': 1.0,\n",
       "     'rcnn_corner_weight': 1.0,\n",
       "     'code_weights': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}},\n",
       "  'POST_PROCESSING': {'RECALL_THRESH_LIST': [0.3, 0.5, 0.7],\n",
       "   'SCORE_THRESH': 0.3,\n",
       "   'OUTPUT_RAW_SCORE': False,\n",
       "   'EVAL_METRIC': 'kitti',\n",
       "   'NMS_CONFIG': {'MULTI_CLASSES_NMS': False,\n",
       "    'NMS_TYPE': 'nms_gpu',\n",
       "    'NMS_THRESH': 0.1,\n",
       "    'NMS_PRE_MAXSIZE': 4096,\n",
       "    'NMS_POST_MAXSIZE': 500}}},\n",
       " 'OPTIMIZATION': {'BATCH_SIZE_PER_GPU': 1,\n",
       "  'NUM_EPOCHS': 80,\n",
       "  'OPTIMIZER': 'adam_onecycle',\n",
       "  'LR': 0.003,\n",
       "  'WEIGHT_DECAY': 0.01,\n",
       "  'MOMENTUM': 0.9,\n",
       "  'MOMS': [0.95, 0.85],\n",
       "  'PCT_START': 0.4,\n",
       "  'DIV_FACTOR': 10,\n",
       "  'DECAY_STEP_LIST': [35, 45],\n",
       "  'LR_DECAY': 0.1,\n",
       "  'LR_CLIP': 1e-07,\n",
       "  'LR_WARMUP': False,\n",
       "  'WARMUP_EPOCH': 1,\n",
       "  'GRAD_NORM_CLIP': 10}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg_from_yaml_file(cfg_file, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_calib_from_file(calib_file):\n",
    "    lines = open(calib_file).readlines()\n",
    "\n",
    "    obj = lines[2].strip().split(' ')[1:]\n",
    "    P2 = np.array(obj, dtype=np.float32)\n",
    "    obj = lines[3].strip().split(' ')[1:]\n",
    "    P3 = np.array(obj, dtype=np.float32)\n",
    "    obj = lines[4].strip().split(' ')[1:]\n",
    "    R0 = np.array(obj, dtype=np.float32)\n",
    "    obj = lines[5].strip().split(' ')[1:]\n",
    "    Tr_velo_to_cam = np.array(obj, dtype=np.float32)\n",
    "\n",
    "    return {'P2': P2.reshape(3, 4),\n",
    "            'P3': P3.reshape(3, 4),\n",
    "            'R0': R0.reshape(3, 3),\n",
    "            'Tr_velo2cam': Tr_velo_to_cam.reshape(3, 4)}\n",
    "\n",
    "def calib_to_matricies(calib):\n",
    "    \"\"\"\n",
    "    Converts calibration object to transformation matricies\n",
    "    Args:\n",
    "        calib: calibration.Calibration, Calibration object\n",
    "    Returns\n",
    "        V2R: (4, 4), Lidar to rectified camera transformation matrix\n",
    "        P2: (3, 4), Camera projection matrix\n",
    "    \"\"\"\n",
    "    V2C = np.vstack((calib.V2C, np.array([0, 0, 0, 1], dtype=np.float32)))  # (4, 4)\n",
    "    R0 = np.hstack((calib.R0, np.zeros((3, 1), dtype=np.float32)))  # (3, 4)\n",
    "    R0 = np.vstack((R0, np.array([0, 0, 0, 1], dtype=np.float32)))  # (4, 4)\n",
    "    V2R = R0 @ V2C\n",
    "    P2 = calib.P2\n",
    "    return V2R, P2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Calibration(object):\n",
    "    def __init__(self, calib_file):\n",
    "        if not isinstance(calib_file, dict):\n",
    "            calib = get_calib_from_file(calib_file)\n",
    "        else:\n",
    "            calib = calib_file\n",
    "\n",
    "        self.P2 = calib['P2']  # 3 x 4\n",
    "        self.R0 = calib['R0']  # 3 x 3\n",
    "        self.V2C = calib['Tr_velo2cam']  # 3 x 4\n",
    "\n",
    "        # Camera intrinsics and extrinsics\n",
    "        self.cu = self.P2[0, 2]\n",
    "        self.cv = self.P2[1, 2]\n",
    "        self.fu = self.P2[0, 0]\n",
    "        self.fv = self.P2[1, 1]\n",
    "        self.tx = self.P2[0, 3] / (-self.fu)\n",
    "        self.ty = self.P2[1, 3] / (-self.fv)\n",
    "\n",
    "    def cart_to_hom(self, pts):\n",
    "        \"\"\"\n",
    "        :param pts: (N, 3 or 2)\n",
    "        :return pts_hom: (N, 4 or 3)\n",
    "        \"\"\"\n",
    "        pts_hom = np.hstack((pts, np.ones((pts.shape[0], 1), dtype=np.float32)))\n",
    "        return pts_hom\n",
    "\n",
    "    def rect_to_lidar(self, pts_rect):\n",
    "        \"\"\"\n",
    "        :param pts_lidar: (N, 3)\n",
    "        :return pts_rect: (N, 3)\n",
    "        \"\"\"\n",
    "        pts_rect_hom = self.cart_to_hom(pts_rect)  # (N, 4)\n",
    "        R0_ext = np.hstack((self.R0, np.zeros((3, 1), dtype=np.float32)))  # (3, 4)\n",
    "        R0_ext = np.vstack((R0_ext, np.zeros((1, 4), dtype=np.float32)))  # (4, 4)\n",
    "        R0_ext[3, 3] = 1\n",
    "        V2C_ext = np.vstack((self.V2C, np.zeros((1, 4), dtype=np.float32)))  # (4, 4)\n",
    "        V2C_ext[3, 3] = 1\n",
    "\n",
    "        pts_lidar = np.dot(pts_rect_hom, np.linalg.inv(np.dot(R0_ext, V2C_ext).T))\n",
    "        return pts_lidar[:, 0:3]\n",
    "\n",
    "    def lidar_to_rect(self, pts_lidar):\n",
    "        \"\"\"\n",
    "        :param pts_lidar: (N, 3)\n",
    "        :return pts_rect: (N, 3)\n",
    "        \"\"\"\n",
    "        pts_lidar_hom = self.cart_to_hom(pts_lidar)\n",
    "        pts_rect = np.dot(pts_lidar_hom, np.dot(self.V2C.T, self.R0.T))\n",
    "        # pts_rect = reduce(np.dot, (pts_lidar_hom, self.V2C.T, self.R0.T))\n",
    "        return pts_rect\n",
    "\n",
    "    def rect_to_img(self, pts_rect):\n",
    "        \"\"\"\n",
    "        :param pts_rect: (N, 3)\n",
    "        :return pts_img: (N, 2)\n",
    "        \"\"\"\n",
    "        pts_rect_hom = self.cart_to_hom(pts_rect)\n",
    "        pts_2d_hom = np.dot(pts_rect_hom, self.P2.T)\n",
    "        pts_img = (pts_2d_hom[:, 0:2].T / pts_rect_hom[:, 2]).T  # (N, 2)\n",
    "        pts_rect_depth = pts_2d_hom[:, 2] - self.P2.T[3, 2]  # depth in rect camera coord\n",
    "        return pts_img, pts_rect_depth\n",
    "\n",
    "    def lidar_to_img(self, pts_lidar):\n",
    "        \"\"\"\n",
    "        :param pts_lidar: (N, 3)\n",
    "        :return pts_img: (N, 2)\n",
    "        \"\"\"\n",
    "        pts_rect = self.lidar_to_rect(pts_lidar)\n",
    "        pts_img, pts_depth = self.rect_to_img(pts_rect)\n",
    "        return pts_img, pts_depth\n",
    "\n",
    "    def img_to_rect(self, u, v, depth_rect):\n",
    "        \"\"\"\n",
    "        :param u: (N)\n",
    "        :param v: (N)\n",
    "        :param depth_rect: (N)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        x = ((u - self.cu) * depth_rect) / self.fu + self.tx\n",
    "        y = ((v - self.cv) * depth_rect) / self.fv + self.ty\n",
    "        pts_rect = np.concatenate((x.reshape(-1, 1), y.reshape(-1, 1), depth_rect.reshape(-1, 1)), axis=1)\n",
    "        return pts_rect\n",
    "\n",
    "    def corners3d_to_img_boxes(self, corners3d):\n",
    "        \"\"\"\n",
    "        :param corners3d: (N, 8, 3) corners in rect coordinate\n",
    "        :return: boxes: (None, 4) [x1, y1, x2, y2] in rgb coordinate\n",
    "        :return: boxes_corner: (None, 8) [xi, yi] in rgb coordinate\n",
    "        \"\"\"\n",
    "        sample_num = corners3d.shape[0]\n",
    "        corners3d_hom = np.concatenate((corners3d, np.ones((sample_num, 8, 1))), axis=2)  # (N, 8, 4)\n",
    "\n",
    "        img_pts = np.matmul(corners3d_hom, self.P2.T)  # (N, 8, 3)\n",
    "\n",
    "        x, y = img_pts[:, :, 0] / img_pts[:, :, 2], img_pts[:, :, 1] / img_pts[:, :, 2]\n",
    "        x1, y1 = np.min(x, axis=1), np.min(y, axis=1)\n",
    "        x2, y2 = np.max(x, axis=1), np.max(y, axis=1)\n",
    "\n",
    "        boxes = np.concatenate((x1.reshape(-1, 1), y1.reshape(-1, 1), x2.reshape(-1, 1), y2.reshape(-1, 1)), axis=1)\n",
    "        boxes_corner = np.concatenate((x.reshape(-1, 8, 1), y.reshape(-1, 8, 1)), axis=2)\n",
    "\n",
    "        return boxes, boxes_corner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch.utils.data as torch_data\n",
    "\n",
    "# from ..utils import common_utils, file_client\n",
    "# from ..pcdet.datasets.augmentor.data_augmentor import DataAugmentor\n",
    "from pcdet.datasets.processor.data_processor import DataProcessor\n",
    "from pcdet.datasets.processor.point_feature_encoder import PointFeatureEncoder\n",
    "\n",
    "class CustomKittiDataset(torch_data.Dataset):\n",
    "    def __init__(self, dataset_cfg=None, class_names=None, training=True, root_path=None, logger=None):\n",
    "        super().__init__()\n",
    "        self.dataset_cfg = dataset_cfg\n",
    "        self.training = training\n",
    "        self.class_names = class_names\n",
    "        self.logger = logger\n",
    "        self.root_path = Path(root_path) if root_path is not None else Path(self.dataset_cfg.DATA_PATH)\n",
    "\n",
    "        self.point_cloud_range = np.array(self.dataset_cfg.POINT_CLOUD_RANGE, dtype=np.float32)\n",
    "        self.point_feature_encoder = PointFeatureEncoder(\n",
    "            self.dataset_cfg.POINT_FEATURE_ENCODING,\n",
    "            point_cloud_range=self.point_cloud_range\n",
    "        )\n",
    "        self.data_processor = DataProcessor(\n",
    "            self.dataset_cfg.DATA_PROCESSOR, point_cloud_range=self.point_cloud_range,\n",
    "            training=self.training, num_point_features=self.point_feature_encoder.num_point_features\n",
    "        )\n",
    "        self.grid_size = self.data_processor.grid_size\n",
    "        self.voxel_size = self.data_processor.voxel_size\n",
    "        self.total_epochs = 0\n",
    "        self.cur_epoch = 0\n",
    "        self._merge_all_iters_to_one_epoch = False\n",
    "\n",
    "    @property\n",
    "    def mode(self):\n",
    "        return 'train' if self.training else 'test'\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        info_path = '/media/rajeev-gupta/Drive250/data/kitti/kitti_infos_test.pkl'\n",
    "        with open(info_path, 'rb') as i_file:\n",
    "            i_dict = pickle.load(i_file)\n",
    "        info = i_dict[index]\n",
    "        \n",
    "        sample_idx = info['point_cloud']['lidar_idx']\n",
    "        img_shape = info['image']['image_shape']\n",
    "        calib = self.get_calib(sample_idx)\n",
    "        get_item_list = self.dataset_cfg.get('GET_ITEM_LIST', ['points'])\n",
    "\n",
    "        input_dict = {\n",
    "            'frame_id': sample_idx,\n",
    "            'calib': calib,\n",
    "        }\n",
    "\n",
    "        if \"points\" in get_item_list:\n",
    "            points = self.get_lidar(sample_idx)\n",
    "            if self.dataset_cfg.FOV_POINTS_ONLY:\n",
    "                pts_rect = calib.lidar_to_rect(points[:, 0:3])\n",
    "                fov_flag = self.get_fov_flag(pts_rect, img_shape, calib)\n",
    "                points = points[fov_flag]\n",
    "            input_dict['points'] = points\n",
    "\n",
    "        if \"image\" in get_item_list:\n",
    "            input_dict['image'] = self.get_image(sample_idx)\n",
    "\n",
    "        if \"calib_matricies\" in get_item_list:\n",
    "            input_dict[\"trans_lidar_to_cam\"], input_dict[\"trans_cam_to_img\"] = calib_to_matricies(calib)\n",
    "\n",
    "        data_dict = self.prepare_data(data_dict=input_dict)\n",
    "\n",
    "        data_dict['image_shape'] = img_shape\n",
    "        return data_dict\n",
    "    \n",
    "    def get_calib(self, idx):\n",
    "        calib_file = self.root_path / 'testing' / 'calib' / ('%s.txt' % idx)\n",
    "        return Calibration(calib_file)\n",
    "\n",
    "    def get_lidar(self, idx):\n",
    "        lidar_file = self.root_path / 'testing' / 'velodyne' / ('%s.bin' % idx)\n",
    "        return np.fromfile(lidar_file, dtype=np.float32).reshape(-1, 4)\n",
    "    \n",
    "    def get_image(self, idx):\n",
    "        img_file = self.root_path / 'testing' / 'image_2' / ('%s.png' % idx)\n",
    "        return cv2.imread(str(img_file), cv2.IMREAD_COLOR)\n",
    "    \n",
    "    def prepare_data(self, data_dict):\n",
    "        if data_dict.get('points', None) is not None:\n",
    "            data_dict = self.point_feature_encoder.forward(data_dict)\n",
    "\n",
    "        data_dict = self.data_processor.forward(\n",
    "            data_dict=data_dict\n",
    "        )\n",
    "        return data_dict\n",
    "\n",
    "    @staticmethod\n",
    "    def get_fov_flag(pts_rect, img_shape, calib):\n",
    "        print('def get_fov_flag ******************')\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pts_rect:\n",
    "            img_shape:\n",
    "            calib:\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        \"\"\"\n",
    "        pts_img, pts_rect_depth = calib.rect_to_img(pts_rect)\n",
    "        val_flag_1 = np.logical_and(pts_img[:, 0] >= 0, pts_img[:, 0] < img_shape[1])\n",
    "        val_flag_2 = np.logical_and(pts_img[:, 1] >= 0, pts_img[:, 1] < img_shape[0])\n",
    "        val_flag_merge = np.logical_and(val_flag_1, val_flag_2)\n",
    "        pts_valid_flag = np.logical_and(val_flag_merge, pts_rect_depth >= 0)\n",
    "\n",
    "        return pts_valid_flag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomKittiDataset(\n",
    "        dataset_cfg=cfg.DATA_CONFIG,\n",
    "        class_names=cfg.CLASS_NAMES,\n",
    "        root_path='/home/rajeev-gupta/sensyn_ws/src/GD-MAE/data/kitti',\n",
    "        training=False,\n",
    "        logger=logger,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = KittiDataset(\n",
    "#         dataset_cfg=cfg.DATA_CONFIG,\n",
    "#         class_names=cfg.CLASS_NAMES,\n",
    "#         root_path=None,\n",
    "#         training=False,\n",
    "#         logger=logger,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11782/2630276673.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGraphRCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCLASS_NAMES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/sensyn_ws/src/GD-MAE/pcdet/models/detectors/graph_rcnn.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_cfg, num_class, dataset, logger)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_cfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_cfg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_cfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_networks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'FREEZE_LAYERS'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFREEZE_LAYERS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sensyn_ws/src/GD-MAE/pcdet/models/detectors/detector3d_template.py\u001b[0m in \u001b[0;36mbuild_networks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_topology\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             module, model_info_dict = getattr(self, 'build_%s' % module_name)(\n\u001b[0;32m---> 56\u001b[0;31m                 \u001b[0mmodel_info_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_info_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             )\n\u001b[1;32m     58\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sensyn_ws/src/GD-MAE/pcdet/models/detectors/detector3d_template.py\u001b[0m in \u001b[0;36mbuild_dense_head\u001b[0;34m(self, model_info_dict)\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mpredict_boxes_when_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ROI_HEAD'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mvoxel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_info_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'voxel_size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             \u001b[0mbackbone_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_info_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'backbone_channels'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         )\n\u001b[1;32m    156\u001b[0m         \u001b[0mmodel_info_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'module_list'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdense_head_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sensyn_ws/src/GD-MAE/pcdet/models/dense_heads/anchor_head_single.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_cfg, input_channels, num_class, class_names, grid_size, point_cloud_range, predict_boxes_when_training, **kwargs)\u001b[0m\n\u001b[1;32m     10\u001b[0m         super().__init__(\n\u001b[1;32m     11\u001b[0m             \u001b[0mmodel_cfg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_cfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrid_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoint_cloud_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpoint_cloud_range\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mpredict_boxes_when_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredict_boxes_when_training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         )\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sensyn_ws/src/GD-MAE/pcdet/models/dense_heads/anchor_head_template.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_cfg, num_class, class_names, grid_size, point_cloud_range, predict_boxes_when_training)\u001b[0m\n\u001b[1;32m     26\u001b[0m         anchors, self.num_anchors_per_location = self.generate_anchors(\n\u001b[1;32m     27\u001b[0m             \u001b[0manchor_generator_cfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrid_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoint_cloud_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpoint_cloud_range\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0manchor_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox_coder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         )\n\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manchors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manchors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sensyn_ws/src/GD-MAE/pcdet/models/dense_heads/anchor_head_template.py\u001b[0m in \u001b[0;36mgenerate_anchors\u001b[0;34m(anchor_generator_cfg, grid_size, point_cloud_range, anchor_ndim)\u001b[0m\n\u001b[1;32m     41\u001b[0m         )\n\u001b[1;32m     42\u001b[0m         \u001b[0mfeature_map_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgrid_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feature_map_stride'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manchor_generator_cfg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0manchors_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_anchors_per_location_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manchor_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_anchors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_map_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0manchor_ndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sensyn_ws/src/GD-MAE/pcdet/models/dense_heads/target_assigner/anchor_generator.py\u001b[0m in \u001b[0;36mgenerate_anchors\u001b[0;34m(self, grid_sizes)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             x_shifts = torch.arange(\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manchor_range\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manchor_range\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_stride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             ).cuda()\n\u001b[1;32m     37\u001b[0m             y_shifts = torch.arange(\n",
      "\u001b[0;32m/media/rajeev-gupta/Drive250/conda_envs/new_graphrcnn/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero."
     ]
    }
   ],
   "source": [
    "model = GraphRCNN(cfg.MODEL, num_class=len(cfg.CLASS_NAMES), dataset=dataset, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'frame_id': array(['000022'], dtype='<U6'),\n",
       " 'calib': array([<pcdet.utils.calibration_kitti.Calibration object at 0x7f1f98d70e10>],\n",
       "       dtype=object),\n",
       " 'points': array([[ 0.0000e+00,  5.6430e+01,  1.1790e+00,  2.1180e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  6.2003e+01,  1.4930e+00,  2.3060e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  4.7137e+01,  6.2750e+00,  1.8170e+00,  9.2000e-01],\n",
       "        ...,\n",
       "        [ 0.0000e+00,  6.3400e+00, -4.1000e-02, -1.6560e+00,  2.7000e-01],\n",
       "        [ 0.0000e+00,  6.3420e+00, -3.1000e-02, -1.6560e+00,  2.3000e-01],\n",
       "        [ 0.0000e+00,  6.3380e+00, -1.1000e-02, -1.6550e+00,  1.8000e-01]],\n",
       "       dtype=float32),\n",
       " 'image': array([[[[ 5.4155402e-02,  1.4589565e-01,  1.8761617e-01, ...,\n",
       "            0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "          [-1.2936717e-01,  3.0806570e-04,  4.3419853e-02, ...,\n",
       "            0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "          [-1.7442521e-01, -4.3367714e-02, -2.0523893e-04, ...,\n",
       "            0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "          ...,\n",
       "          [-8.7051606e-01, -8.4891206e-01, -8.3758187e-01, ...,\n",
       "            0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "          [-8.8378406e-01, -9.3620706e-01, -9.6325076e-01, ...,\n",
       "            0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "          [-8.9689279e-01, -9.4931579e-01, -9.6402365e-01, ...,\n",
       "            0.0000000e+00,  0.0000000e+00,  0.0000000e+00]],\n",
       " \n",
       "         [[-4.5834222e-01, -3.7553135e-01, -3.8595867e-01, ...,\n",
       "            0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "          [-4.8595220e-01, -3.8982472e-01, -3.7378159e-01, ...,\n",
       "            0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "          [-5.0042784e-01, -4.1680831e-01, -4.0027714e-01, ...,\n",
       "            0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "          ...,\n",
       "          [-1.1451260e+00, -1.1321329e+00, -1.1316563e+00, ...,\n",
       "            0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "          [-1.1446229e+00, -1.1446229e+00, -1.1446229e+00, ...,\n",
       "            0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "          [-1.1308179e+00, -1.1308179e+00, -1.1308179e+00, ...,\n",
       "            0.0000000e+00,  0.0000000e+00,  0.0000000e+00]],\n",
       " \n",
       "         [[-6.8979764e-01, -7.1700269e-01, -8.5069984e-01, ...,\n",
       "            0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "          [-6.8979764e-01, -7.0387840e-01, -8.3709419e-01, ...,\n",
       "            0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "          [-6.7652249e-01, -6.6451406e-01, -7.3431098e-01, ...,\n",
       "            0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "          ...,\n",
       "          [-1.2405781e+00, -1.2533836e+00, -1.2405832e+00, ...,\n",
       "            0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "          [-1.2553405e+00, -1.2553405e+00, -1.2416040e+00, ...,\n",
       "            0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "          [-1.2961574e+00, -1.2961574e+00, -1.2696176e+00, ...,\n",
       "            0.0000000e+00,  0.0000000e+00,  0.0000000e+00]]]],\n",
       "       dtype=float32),\n",
       " 'trans_lidar_to_cam': array([[[ 2.3477380e-04, -9.9994415e-01, -1.0563477e-02, -2.7968171e-03],\n",
       "         [ 1.0449408e-02,  1.0565354e-02, -9.9988961e-01, -7.5108789e-02],\n",
       "         [ 9.9994540e-01,  1.2436544e-04,  1.0451303e-02, -2.7213278e-01],\n",
       "         [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0000000e+00]]],\n",
       "       dtype=float32),\n",
       " 'trans_cam_to_img': array([[[7.215377e+02, 0.000000e+00, 6.095593e+02, 4.485728e+01],\n",
       "         [0.000000e+00, 7.215377e+02, 1.728540e+02, 2.163791e-01],\n",
       "         [0.000000e+00, 0.000000e+00, 1.000000e+00, 2.745884e-03]]],\n",
       "       dtype=float32),\n",
       " 'use_lead_xyz': array([ True]),\n",
       " 'transformation_2d_list': [['imrescale']],\n",
       " 'transformation_2d_params': [{'imrescale': [1.0241545893719808, 1.024]}],\n",
       " 'image_rescale_shape': array([[ 384, 1272]]),\n",
       " 'image_pad_shape': array([[ 384, 1280]]),\n",
       " 'image_shape': array([[ 375, 1242]], dtype=int32),\n",
       " 'batch_size': 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/home/rajeev-gupta/sensyn_ws/src/GD-MAE/tools/batch_dict_22', 'rb') as b_file:\n",
    "    b_dict = pickle.load(b_file)\n",
    "print(type(b_dict))\n",
    "b_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def get_fov_flag ******************\n",
      "point is not None\n",
      "from def forward ******************\n",
      "from def mask_points_and_boxes_outside_range ******************\n",
      "from def shuffle_points ******************\n",
      "from def calculate_grid_size ******************\n",
      "from def imrescale ******************\n",
      "from def imflip ******************\n",
      "from def imnormalize ******************\n",
      "from def impad ******************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'frame_id': '000004',\n",
       " 'calib': <__main__.Calibration at 0x7f1f98d6ed90>,\n",
       " 'points': array([[ 3.7786e+01,  7.8970e+00,  1.5140e+00,  9.4000e-01],\n",
       "        [ 3.7753e+01,  8.0140e+00,  1.5140e+00,  9.9000e-01],\n",
       "        [ 3.7741e+01,  8.1360e+00,  1.5150e+00,  9.9000e-01],\n",
       "        ...,\n",
       "        [ 6.3800e+00, -3.2000e-02, -1.6670e+00,  2.2000e-01],\n",
       "        [ 6.3980e+00, -2.2000e-02, -1.6720e+00,  2.1000e-01],\n",
       "        [ 6.3770e+00, -1.0000e-03, -1.6660e+00,  1.2000e-01]],\n",
       "       dtype=float32),\n",
       " 'image': array([[[-1.277312  , -1.5028257 , -1.5781852 ],\n",
       "         [-1.277312  , -1.5028257 , -1.5781852 ],\n",
       "         [-1.2908984 , -1.4599018 , -1.5781852 ],\n",
       "         ...,\n",
       "         [ 0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ]],\n",
       " \n",
       "        [[-1.3044848 , -1.4885178 , -1.5781852 ],\n",
       "         [-1.277312  , -1.5028257 , -1.5781852 ],\n",
       "         [-1.277312  , -1.4885178 , -1.5922866 ],\n",
       "         ...,\n",
       "         [ 0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ]],\n",
       " \n",
       "        [[-1.3044848 , -1.5028257 , -1.5922866 ],\n",
       "         [-1.277312  , -1.4885178 , -1.5922866 ],\n",
       "         [-1.277312  , -1.4885178 , -1.5922866 ],\n",
       "         ...,\n",
       "         [ 0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.38022906,  0.29998145,  0.2831982 ],\n",
       "         [ 0.38022906,  0.29998145,  0.33960375],\n",
       "         [ 0.38022906,  0.34290543,  0.19858986],\n",
       "         ...,\n",
       "         [ 0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ]],\n",
       " \n",
       "        [[ 0.28512424,  0.31428945,  0.35370514],\n",
       "         [ 0.27153784,  0.29998145,  0.36780652],\n",
       "         [ 0.27153784,  0.31428945,  0.17038709],\n",
       "         ...,\n",
       "         [ 0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ]],\n",
       " \n",
       "        [[ 0.23077863,  0.14259352,  0.07167736],\n",
       "         [ 0.27153784,  0.12828553,  0.04347458],\n",
       "         [ 0.27153784,  0.14259352, -0.08343792],\n",
       "         ...,\n",
       "         [ 0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ]]], dtype=float32),\n",
       " 'trans_lidar_to_cam': array([[ 2.3477380e-04, -9.9994415e-01, -1.0563477e-02, -2.7968171e-03],\n",
       "        [ 1.0449408e-02,  1.0565354e-02, -9.9988961e-01, -7.5108789e-02],\n",
       "        [ 9.9994540e-01,  1.2436544e-04,  1.0451303e-02, -2.7213278e-01],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0000000e+00]],\n",
       "       dtype=float32),\n",
       " 'trans_cam_to_img': array([[7.215377e+02, 0.000000e+00, 6.095593e+02, 4.485728e+01],\n",
       "        [0.000000e+00, 7.215377e+02, 1.728540e+02, 2.163791e-01],\n",
       "        [0.000000e+00, 0.000000e+00, 1.000000e+00, 2.745884e-03]],\n",
       "       dtype=float32),\n",
       " 'use_lead_xyz': True,\n",
       " 'transformation_2d_list': ['imrescale'],\n",
       " 'transformation_2d_params': {'imrescale': (1.0241545893719808, 1.024)},\n",
       " 'image_rescale_shape': (384, 1272),\n",
       " 'image_pad_shape': (384, 1280),\n",
       " 'image_shape': array([ 375, 1242], dtype=int32)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_dict = dataset.__getitem__(4)\n",
    "get_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame_id\n",
      "calib\n",
      "points\n",
      "image\n",
      "trans_lidar_to_cam\n",
      "trans_cam_to_img\n",
      "use_lead_xyz\n",
      "transformation_2d_list\n",
      "transformation_2d_params\n",
      "image_rescale_shape\n",
      "image_pad_shape\n",
      "image_shape\n"
     ]
    }
   ],
   "source": [
    "for key, val in get_dict.items():\n",
    "    print(key)\n",
    "    if type(val) == tuple:\n",
    "        get_dict[key] = list(val)\n",
    "    elif key == 'points':\n",
    "        # add a zero column\n",
    "        n = val.shape[0]\n",
    "        z_col = np.zeros((n, 1), dtype=float)\n",
    "        get_dict[key] = np.concatenate((z_col, val), axis = 1)\n",
    "        continue\n",
    "    elif key == 'image':\n",
    "        # transpose (384, 1280, 3) to (3, 384, 1280)\n",
    "        val_transposed = np.transpose(val, (2, 0, 1))\n",
    "        get_dict[key] = val_transposed\n",
    "        # print(get_dict[key].shape)\n",
    "    elif key == 'transformation_2d_list' or key == 'transformation_2d_params':\n",
    "        get_dict[key] = [val]\n",
    "        continue\n",
    "    get_dict[key] = np.array([get_dict[key]])\n",
    "            \n",
    "get_dict['batch_size'] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'frame_id': array(['000004'], dtype='<U6'),\n",
       " 'calib': array([<__main__.Calibration object at 0x7f1f98d6ed90>], dtype=object),\n",
       " 'points': array([[ 0.00000000e+00,  3.77859993e+01,  7.89699984e+00,\n",
       "          1.51400006e+00,  9.39999998e-01],\n",
       "        [ 0.00000000e+00,  3.77529984e+01,  8.01399994e+00,\n",
       "          1.51400006e+00,  9.90000010e-01],\n",
       "        [ 0.00000000e+00,  3.77410011e+01,  8.13599968e+00,\n",
       "          1.51499999e+00,  9.90000010e-01],\n",
       "        ...,\n",
       "        [ 0.00000000e+00,  6.38000011e+00, -3.20000015e-02,\n",
       "         -1.66700006e+00,  2.19999999e-01],\n",
       "        [ 0.00000000e+00,  6.39799976e+00, -2.19999999e-02,\n",
       "         -1.67200005e+00,  2.09999993e-01],\n",
       "        [ 0.00000000e+00,  6.37699986e+00, -1.00000005e-03,\n",
       "         -1.66600001e+00,  1.19999997e-01]]),\n",
       " 'image': array([[[[-1.277312  , -1.277312  , -1.2908984 , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [-1.3044848 , -1.277312  , -1.277312  , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [-1.3044848 , -1.277312  , -1.277312  , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          ...,\n",
       "          [ 0.38022906,  0.38022906,  0.38022906, ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.28512424,  0.27153784,  0.27153784, ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.23077863,  0.27153784,  0.27153784, ...,  0.        ,\n",
       "            0.        ,  0.        ]],\n",
       " \n",
       "         [[-1.5028257 , -1.5028257 , -1.4599018 , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [-1.4885178 , -1.5028257 , -1.4885178 , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [-1.5028257 , -1.4885178 , -1.4885178 , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          ...,\n",
       "          [ 0.29998145,  0.29998145,  0.34290543, ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.31428945,  0.29998145,  0.31428945, ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.14259352,  0.12828553,  0.14259352, ...,  0.        ,\n",
       "            0.        ,  0.        ]],\n",
       " \n",
       "         [[-1.5781852 , -1.5781852 , -1.5781852 , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [-1.5781852 , -1.5781852 , -1.5922866 , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [-1.5922866 , -1.5922866 , -1.5922866 , ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          ...,\n",
       "          [ 0.2831982 ,  0.33960375,  0.19858986, ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.35370514,  0.36780652,  0.17038709, ...,  0.        ,\n",
       "            0.        ,  0.        ],\n",
       "          [ 0.07167736,  0.04347458, -0.08343792, ...,  0.        ,\n",
       "            0.        ,  0.        ]]]], dtype=float32),\n",
       " 'trans_lidar_to_cam': array([[[ 2.3477380e-04, -9.9994415e-01, -1.0563477e-02, -2.7968171e-03],\n",
       "         [ 1.0449408e-02,  1.0565354e-02, -9.9988961e-01, -7.5108789e-02],\n",
       "         [ 9.9994540e-01,  1.2436544e-04,  1.0451303e-02, -2.7213278e-01],\n",
       "         [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0000000e+00]]],\n",
       "       dtype=float32),\n",
       " 'trans_cam_to_img': array([[[7.215377e+02, 0.000000e+00, 6.095593e+02, 4.485728e+01],\n",
       "         [0.000000e+00, 7.215377e+02, 1.728540e+02, 2.163791e-01],\n",
       "         [0.000000e+00, 0.000000e+00, 1.000000e+00, 2.745884e-03]]],\n",
       "       dtype=float32),\n",
       " 'use_lead_xyz': array([ True]),\n",
       " 'transformation_2d_list': [['imrescale']],\n",
       " 'transformation_2d_params': [{'imrescale': (1.0241545893719808, 1.024)}],\n",
       " 'image_rescale_shape': array([[ 384, 1272]]),\n",
       " 'image_pad_shape': array([[ 384, 1280]]),\n",
       " 'image_shape': array([[ 375, 1242]], dtype=int32),\n",
       " 'batch_size': 1}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_dict == b_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "points (19639, 5) (17458, 5)\n"
     ]
    }
   ],
   "source": [
    "for key in get_dict.keys():\n",
    "    if type(b_dict[key]) == np.ndarray:\n",
    "        if get_dict[key].shape != b_dict[key].shape:\n",
    "            print(key, get_dict[key].shape, b_dict[key].shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from detector3d_template.py: def load_params_from_file ******************"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-30 20:15:42,564   INFO  ==> Loading parameters from checkpoint /home/rajeev-gupta/sensyn_ws/src/GD-MAE/data/ckpts/graph_rcnn_voi_kitti.pth to GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-30 20:15:43,113   INFO  ==> Done (loaded 518/518)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from detector3d_template.py: def _load_state_dict ******************\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.load_params_from_file(filename=ckpt_path, logger=logger, to_cpu=to_cpu)\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from detector3d_template.py: def post_processing ******************\n",
      "from detector3d_template.py: def generate_recall_record ******************\n",
      "Inference Time:  2.7641761302948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'pred_boxes': tensor([[37.7703, 15.6945, -0.3821,  4.1330,  1.7591,  1.4665,  3.1287]],\n",
       "         device='cuda:0', grad_fn=<IndexBackward0>),\n",
       "  'pred_scores': tensor([0.9051], device='cuda:0', grad_fn=<IndexBackward0>),\n",
       "  'pred_labels': tensor([1], device='cuda:0')}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_input = get_dict\n",
    "# data_input = b_dict\n",
    "torch.cuda.synchronize()\n",
    "start_time = time.time()\n",
    "load_data_to_gpu(data_input)\n",
    "pred_dicts, ret_dict = model(data_input)\n",
    "torch.cuda.synchronize()\n",
    "end_time = time.time()\n",
    "print('Inference Time: ', end_time-start_time)\n",
    "\n",
    "pred_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['frame_id',\n",
       " 'calib',\n",
       " 'points',\n",
       " 'image',\n",
       " 'trans_lidar_to_cam',\n",
       " 'trans_cam_to_img',\n",
       " 'use_lead_xyz',\n",
       " 'transformation_2d_list',\n",
       " 'transformation_2d_params',\n",
       " 'image_rescale_shape',\n",
       " 'image_pad_shape',\n",
       " 'image_shape',\n",
       " 'batch_size']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = list(b_dict.keys())\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'frame_id': array(['000022'], dtype='<U6'),\n",
       " 'calib': array([<pcdet.utils.calibration_kitti.Calibration object at 0x7f1f98d70e10>],\n",
       "       dtype=object),\n",
       " 'points': array([[ 0.0000e+00,  5.6430e+01,  1.1790e+00,  2.1180e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  6.2003e+01,  1.4930e+00,  2.3060e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  4.7137e+01,  6.2750e+00,  1.8170e+00,  9.2000e-01],\n",
       "        ...,\n",
       "        [ 0.0000e+00,  6.3400e+00, -4.1000e-02, -1.6560e+00,  2.7000e-01],\n",
       "        [ 0.0000e+00,  6.3420e+00, -3.1000e-02, -1.6560e+00,  2.3000e-01],\n",
       "        [ 0.0000e+00,  6.3380e+00, -1.1000e-02, -1.6550e+00,  1.8000e-01]],\n",
       "       dtype=float32),\n",
       " 'image': array([[[[ 5.4155402e-02,  1.4589565e-01,  1.8761617e-01, ...,\n",
       "            0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "          [-1.2936717e-01,  3.0806570e-04,  4.3419853e-02, ...,\n",
       "            0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "          [-1.7442521e-01, -4.3367714e-02, -2.0523893e-04, ...,\n",
       "            0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "          ...,\n",
       "          [-8.7051606e-01, -8.4891206e-01, -8.3758187e-01, ...,\n",
       "            0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "          [-8.8378406e-01, -9.3620706e-01, -9.6325076e-01, ...,\n",
       "            0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "          [-8.9689279e-01, -9.4931579e-01, -9.6402365e-01, ...,\n",
       "            0.0000000e+00,  0.0000000e+00,  0.0000000e+00]],\n",
       " \n",
       "         [[-4.5834222e-01, -3.7553135e-01, -3.8595867e-01, ...,\n",
       "            0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "          [-4.8595220e-01, -3.8982472e-01, -3.7378159e-01, ...,\n",
       "            0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "          [-5.0042784e-01, -4.1680831e-01, -4.0027714e-01, ...,\n",
       "            0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "          ...,\n",
       "          [-1.1451260e+00, -1.1321329e+00, -1.1316563e+00, ...,\n",
       "            0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "          [-1.1446229e+00, -1.1446229e+00, -1.1446229e+00, ...,\n",
       "            0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "          [-1.1308179e+00, -1.1308179e+00, -1.1308179e+00, ...,\n",
       "            0.0000000e+00,  0.0000000e+00,  0.0000000e+00]],\n",
       " \n",
       "         [[-6.8979764e-01, -7.1700269e-01, -8.5069984e-01, ...,\n",
       "            0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "          [-6.8979764e-01, -7.0387840e-01, -8.3709419e-01, ...,\n",
       "            0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "          [-6.7652249e-01, -6.6451406e-01, -7.3431098e-01, ...,\n",
       "            0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "          ...,\n",
       "          [-1.2405781e+00, -1.2533836e+00, -1.2405832e+00, ...,\n",
       "            0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "          [-1.2553405e+00, -1.2553405e+00, -1.2416040e+00, ...,\n",
       "            0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "          [-1.2961574e+00, -1.2961574e+00, -1.2696176e+00, ...,\n",
       "            0.0000000e+00,  0.0000000e+00,  0.0000000e+00]]]],\n",
       "       dtype=float32),\n",
       " 'trans_lidar_to_cam': array([[[ 2.3477380e-04, -9.9994415e-01, -1.0563477e-02, -2.7968171e-03],\n",
       "         [ 1.0449408e-02,  1.0565354e-02, -9.9988961e-01, -7.5108789e-02],\n",
       "         [ 9.9994540e-01,  1.2436544e-04,  1.0451303e-02, -2.7213278e-01],\n",
       "         [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0000000e+00]]],\n",
       "       dtype=float32),\n",
       " 'trans_cam_to_img': array([[[7.215377e+02, 0.000000e+00, 6.095593e+02, 4.485728e+01],\n",
       "         [0.000000e+00, 7.215377e+02, 1.728540e+02, 2.163791e-01],\n",
       "         [0.000000e+00, 0.000000e+00, 1.000000e+00, 2.745884e-03]]],\n",
       "       dtype=float32),\n",
       " 'use_lead_xyz': array([ True]),\n",
       " 'transformation_2d_list': [['imrescale']],\n",
       " 'transformation_2d_params': [{'imrescale': [1.0241545893719808, 1.024]}],\n",
       " 'image_rescale_shape': array([[ 384, 1272]]),\n",
       " 'image_pad_shape': array([[ 384, 1280]]),\n",
       " 'image_shape': array([[ 375, 1242]], dtype=int32),\n",
       " 'batch_size': 1}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def get_fov_flag ******************\n",
      "point is not None\n",
      "from def forward ******************\n",
      "from def mask_points_and_boxes_outside_range ******************\n",
      "from def shuffle_points ******************\n",
      "from def calculate_grid_size ******************\n",
      "from def imrescale ******************\n",
      "from def imflip ******************\n",
      "from def imnormalize ******************\n",
      "from def impad ******************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset.__getitem__(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_path = '/media/rajeev-gupta/Drive250/data/kitti/kitti_infos_test.pkl'\n",
    "with open(info_path, 'rb') as i_file:\n",
    "    i_dict = pickle.load(i_file)\n",
    "len(i_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'point_cloud': {'num_features': 4, 'lidar_idx': '000000'},\n",
       " 'image': {'image_idx': '000000',\n",
       "  'image_shape': array([ 375, 1242], dtype=int32)},\n",
       " 'calib': {'P2': array([[7.21537720e+02, 0.00000000e+00, 6.09559326e+02, 4.48572807e+01],\n",
       "         [0.00000000e+00, 7.21537720e+02, 1.72854004e+02, 2.16379106e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 2.74588400e-03],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00]]),\n",
       "  'R0_rect': array([[ 0.9999239 ,  0.00983776, -0.00744505,  0.        ],\n",
       "         [-0.0098698 ,  0.9999421 , -0.00427846,  0.        ],\n",
       "         [ 0.00740253,  0.00435161,  0.9999631 ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  1.        ]],\n",
       "        dtype=float32),\n",
       "  'Tr_velo_to_cam': array([[ 7.53374491e-03, -9.99971390e-01, -6.16602018e-04,\n",
       "          -4.06976603e-03],\n",
       "         [ 1.48024904e-02,  7.28073297e-04, -9.99890208e-01,\n",
       "          -7.63161778e-02],\n",
       "         [ 9.99862075e-01,  7.52379000e-03,  1.48075502e-02,\n",
       "          -2.71780610e-01],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "           1.00000000e+00]])}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_dict[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def process_file(file_path, keyword):\n",
    "    if not os.path.isfile(file_path):\n",
    "        print(f\"The file {file_path} does not exist.\")\n",
    "        return\n",
    "    \n",
    "    # Read the file content\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    save_path = file_path[:-3] + '2' + file_path[-3:]\n",
    "    base_name = os.path.basename(file_path)\n",
    "    # Find lines containing the keyword\n",
    "    line_dict = {index: line for index, line in enumerate(lines) if keyword in line}\n",
    "\n",
    "    # Insert comments below each found line\n",
    "    for index in sorted(line_dict.keys(), reverse=True):  # Process in reverse order to avoid shifting lines\n",
    "        line = line_dict[index][:-1]\n",
    "        i = 0\n",
    "        while(line[i]==' '):\n",
    "            i+=1\n",
    "        j = i\n",
    "        while(line[j]!='('):\n",
    "            j+=1\n",
    "        lines.insert(index + 1, f\"{line[:i]}    print('from {base_name}: {line[i:j]} ******************')\\n\")\n",
    "\n",
    "    # Write the modified content back to the file\n",
    "    with open(save_path, 'w') as file:\n",
    "        file.writelines(lines)\n",
    "\n",
    "    print(f\"Processed file {file_path} successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def process_file_del(file_path, keyword):\n",
    "    if not os.path.isfile(file_path):\n",
    "        print(f\"The file {file_path} does not exist.\")\n",
    "        return\n",
    "    \n",
    "    # Read the file content\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    save_path = file_path[:-3] + '2' + file_path[-3:]\n",
    "    # Find lines containing the keyword\n",
    "    line_dict = {index: line for index, line in enumerate(lines) if keyword in line}\n",
    "\n",
    "    # Insert comments below each found line\n",
    "    for index in sorted(line_dict.keys(), reverse=True):  # Process in reverse order to avoid shifting lines\n",
    "        del lines[index]\n",
    "    # Write the modified content back to the file\n",
    "    with open(save_path, 'w') as file:\n",
    "        file.writelines(lines)\n",
    "\n",
    "    print(f\"Processed file {file_path} successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file /home/rajeev-gupta/sensyn_ws/src/GD-MAE/pcdet/datasets/kitti/kitti_dataset.py successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# file_path = '/home/rajeev-gupta/sensyn_ws/src/GD-MAE/pcdet/datasets/kitti/kitti_dataset.py'  # Replace with your file path\n",
    "# keyword = '******************\\')'\n",
    "# process_file_del(file_path, keyword)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file /home/rajeev-gupta/sensyn_ws/src/GD-MAE/pcdet/datasets/dataset.py successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# file_path = '/home/rajeev-gupta/sensyn_ws/src/GD-MAE/pcdet/datasets/dataset.py'  # Replace with your file path\n",
    "# keyword = '******************\\')'\n",
    "# process_file_del(file_path, keyword)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file /home/rajeev-gupta/sensyn_ws/src/GD-MAE/pcdet/models/detectors/detector3d_template.py successfully.\n"
     ]
    }
   ],
   "source": [
    "# file_path = '/home/rajeev-gupta/sensyn_ws/src/GD-MAE/pcdet/models/detectors/detector3d_template.py'  # Replace with your file path\n",
    "# keyword = '******************\\')'\n",
    "# process_file_del(file_path, keyword)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file /home/rajeev-gupta/sensyn_ws/src/GD-MAE/pcdet/datasets/processor/data_processor.py successfully.\n"
     ]
    }
   ],
   "source": [
    "file_path = '/home/rajeev-gupta/sensyn_ws/src/GD-MAE/pcdet/datasets/processor/data_processor.py'  # Replace with your file path\n",
    "keyword = '******************\\')'\n",
    "process_file_del(file_path, keyword)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
